{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class Axis(object):\n",
    "    '''A generic parent class - set up the disk on a chosen 2d grid (can later make 3d is needed .. )\n",
    "    Specify either the points (2 - 1D r and phi arrays) or bounds on r and phi + num_points or deltas\n",
    "    - The output of this class is 2d arrays of r & phi using meshgrid ...\n",
    "    '''\n",
    "    def __init__(self, points_r=None,points_phi=None, bounds_r=None,bounds_phi=None, \\\n",
    "                 num_points=10,delta_r=None,delta_phi=None,axis_type='TwoD_cyl'):\n",
    "        self.axis_type = axis_type\n",
    "        defaultUnits = {'r': 'AU',\n",
    "                        'phi': 'degree'}\n",
    "        if points_r is not None:\n",
    "            try:\n",
    "                points_r = np.atleast_1d(np.array(points_r, dtype=float))\n",
    "                points_phi = np.atleast_1d(np.array(points_phi, dtype=float))\n",
    "            except:\n",
    "                raise ValueError('points must be array_like.')\n",
    "        if bounds_r is not None:\n",
    "            try:\n",
    "                bounds_r = np.sort(np.atleast_1d(np.array(bounds_r, dtype=float)))\n",
    "                bounds_phi = np.sort(np.atleast_1d(np.array(bounds_phi, dtype=float)))\n",
    "            except:\n",
    "                raise ValueError('bounds must be array_like.')\n",
    "\n",
    "        if bounds_r is None:\n",
    "            if points_r is not None:\n",
    "                # only points are given - so use the default bounds in addition to the points.\n",
    "                bounds_r = np.array([points_r.min(),points_r.max()])\n",
    "                bounds_phi = np.array([points_phi.min(),points_phi.max()])\n",
    "            else:\n",
    "                raise ValueError('Specify either bounds or points')\n",
    "        else:  # bounds are given\n",
    "            if points_r is None:\n",
    "                # create an evenly spaced axis\n",
    "                if delta_r is not None :\n",
    "                    end0 = np.min(bounds_r)\n",
    "                    end1 = np.max(bounds_r)\n",
    "                    points_r = np.arange(end0,end1+delta_r/2.,delta_r)\n",
    "                    end0 = np.min(bounds_phi)\n",
    "                    end1 = np.max(bounds_phi)\n",
    "                    points_phi = np.arange(end0,end1+delta_phi/2.,delta_phi)\n",
    "                else :\n",
    "                    end0 = np.min(bounds_r)\n",
    "                    end1 = np.max(bounds_r)\n",
    "                    delta = (end1 - end0) / num_points\n",
    "                    points_r = np.linspace(end0, end1, num_points)\n",
    "                    end0 = np.min(bounds_phi)\n",
    "                    end1 = np.max(bounds_phi)\n",
    "                    delta = (end1 - end0) / num_points\n",
    "                    points_phi = np.linspace(end0, end1, num_points)\n",
    "            else:\n",
    "                # points and bounds both given, over-write the bounds ...\n",
    "                print('Overwriting the bounds to match the points')\n",
    "                bounds_r = np.array([points_r.min(),points_r.max()])\n",
    "                bounds_phi = np.array([points_phi.min(),points_phi.max()])\n",
    "\n",
    "        X, Y = np.meshgrid(points_r, points_phi)\n",
    "        self.num_points = X.size\n",
    "        self.shape = np.array([points_r.size,points_phi.size])\n",
    "        self.units = defaultUnits\n",
    "        self.points_r = X\n",
    "        self.bounds_r = bounds_r\n",
    "        self.points_phi = Y\n",
    "        self.bounds_phi = bounds_phi\n",
    "        area1 = np.pi*(bounds_r[1]**2. - bounds_r[0]**2.)\n",
    "        area2 = (bounds_phi[1] - bounds_phi[0])/2./np.pi\n",
    "        tmp1  = X**2. \n",
    "        tmp2 = np.diff(tmp1,axis=1)\n",
    "        tmp3 = np.diff(Y,axis=0)/2./np.pi\n",
    "        self.area_all = area1*area2\n",
    "        self.area_grid = np.pi*tmp2[:-1,:]*tmp3[:,:-1]\n",
    "        self.num_grid_pt = self.area_grid.flatten().shape[0]\n",
    "        \n",
    "## Some code to get general disk properties ..\n",
    "\n",
    "import numpy as np\n",
    "import astropy.constants as const\n",
    "\n",
    "# mmsn - sigma1 (g/cm^2) and T1 (Kelvin) are density and temp at 1 AU. r_disk in AU\n",
    "def mmsn_model(R_disk,alphav,Sigma1 =1700.,T1 = 270.):\n",
    "    sigma_r = Sigma1*R_disk**(-1.5)\n",
    "    t_gas_r = T1*R_disk**(-.5)\n",
    "    tmp1 = R_disk*const.au.cgs.value\n",
    "    tmp2 = const.G.cgs.value*const.M_sun.cgs.value\n",
    "    mean_mol_weigth = 2.34*const.m_p.cgs.value\n",
    "    omega = np.sqrt(tmp2/(tmp1)**3.) # orbital angular velocity\n",
    "    c_s = np.sqrt(const.k_B.cgs.value*t_gas_r/mean_mol_weigth) # gas sound speed, cm\n",
    "    H_disk = c_s/omega\n",
    "    rhog = (1./np.sqrt(2.*np.pi))*sigma_r/H_disk           # Gas Volume Density\n",
    "    t_L,L_Scale,vel_L,t_kol,l_kol,v_kol,Re = turb_param(c_s,H_disk,alphav,rhog,omega)\n",
    "    lmfp = mean_mol_weigth/np.sqrt(2.)/2e-15/rhog    # cm\n",
    "    vk = R_disk*omega*const.au.cgs.value\n",
    "    return sigma_r,t_gas_r,c_s,t_L,L_Scale,vel_L, t_kol,l_kol,v_kol,Re,lmfp,vk,H_disk\n",
    "\n",
    "def turb_param(c_s,H_disk,alphav,rhog,omega):\n",
    "    t_L = 1./omega\n",
    "    L_Scale = np.sqrt(alphav)*H_disk # equate L^2/t_overturn ~ L^2*(omega) ~ alphav*c_s*H_disk\n",
    "    vel_L  = np.sqrt(alphav)*c_s\n",
    "    v_tub = alphav*c_s*H_disk\n",
    "    v_mol = .5*np.sqrt(8./np.pi)*c_s*2.4*const.m_p.cgs.value/np.sqrt(2.)/2e-15/rhog\n",
    "    Re = v_tub/v_mol\n",
    "    l_kol = L_Scale/Re**(3./4.)\n",
    "    t_kol = t_L/np.sqrt(Re)\n",
    "    v_kol = l_kol/t_kol\n",
    "    return t_L,L_Scale,vel_L,t_kol,l_kol,v_kol,Re\n",
    "\n",
    "\n",
    "## This is for giving an array of particle1, particle2 and output a grid of relative velocities for all combinations ...\n",
    "## Need an equal shapes of particle_1 and particle_2 arrays\n",
    "def rel_velocity_grd(particle_1,particle_2,M_star,R_dust,Temp_g,St1=None,St2=None,alphav = 1e-3,sigmaD = 1000.,psi = .01,H_disk = .1,rhod1=3.,rhod2=3.):\n",
    "    # Input Paramters\n",
    "    #Temp = 300 # Kelvin\n",
    "    #R = 1. #AU\n",
    "    #alphav = 1e-3          # Alpha-turbulence\n",
    "    #sigmaD = 1000.           # gm/cm^2 - Gas Surface Density at Chosen Location ...\n",
    "    #psi = .01\t# Dust/Gas Mass ratio\n",
    "    #H = .1 \t\t# Scale Heigh (AU)\n",
    "    #particle_1 = logspace(-4,6,100)\n",
    "    #particle_2 = logspace(-4,6,100)\n",
    "    #if(particle_1.shape != particle_2.shape):\n",
    "    #    print('Need equal shapes of particle_1 and particle_2 arrays')\n",
    "    #    pass\n",
    "    H_disk = H_disk/const.au.cgs.value \n",
    "    tmp1 = R_dust*const.au.cgs.value\n",
    "    tmp2 = M_star*const.G.cgs.value*const.M_sun.cgs.value\n",
    "    vk = np.sqrt(tmp2/tmp1)\n",
    "    omega = np.sqrt(tmp2/(tmp1)**3.) # orbital angular velocity\n",
    "    mean_mol_weigth = 2.4*const.m_p.cgs.value\n",
    "    cs = np.sqrt(const.k_B.cgs.value*Temp_g/mean_mol_weigth) # gas sound speed\n",
    "    rhog = (1./np.sqrt(2.*np.pi))*sigmaD/H_disk/const.au.cgs.value           # Gas Volume Density\n",
    "    mfp = (2.4*const.m_p.cgs.value)/rhog/2e-15/np.sqrt(2)\t# Gas mean Free Path\n",
    "    cnst1_1 = (4./9.)*1e-15*(rhod1*omega)/((2.4*const.m_p.cgs.value)*cs)\n",
    "    cnst1_2 = (4./9.)*1e-15*(rhod2*omega)/((2.4*const.m_p.cgs.value)*cs)\n",
    "    u_n = cs**2./2./vk\n",
    "    vg2 = (np.sqrt(alphav)*cs)**2.\n",
    "    beta = (H_disk/R_dust)**2.\n",
    "    Re_u = 1./np.sqrt(alphav*cs*cs/omega/mfp/cs)\n",
    "    ############################################################\n",
    "    ############################################################\n",
    "    m1 = (4.*np.pi/3.)*(particle_1**3.)*rhod1\n",
    "    m2 = (4.*np.pi/3.)*(particle_2**3.)*rhod2\n",
    "    ############################################################\n",
    "    if St1 is None :\n",
    "        St1 = (particle_1)*(rhod1*omega)/(rhog*cs)\n",
    "        tmp1 = np.where(particle_1 > mfp*9./4.)\n",
    "        St1[tmp1] = cnst1_1*(particle_1[tmp1])**2.  # Stokes Drag Regime\n",
    "        \n",
    "        St2 = (particle_2)*(rhod2*omega)/(rhog*cs)\n",
    "        tmp1 = np.where(particle_2 > mfp*9./4.)\n",
    "        St2[tmp1] = cnst1_2*(particle_2[tmp1])**2.  # Stokes Drag Regime\n",
    "    ############################################################\n",
    "    num = particle_1.shape[0]\n",
    "    num2 = particle_2.shape[0]\n",
    "    vel_browm = np.zeros([num,num2])\n",
    "    vel_drift = np.zeros([num,num2])\n",
    "    vel_drift_th = np.zeros([num,num2])\n",
    "    vel_turb= np.zeros([num,num2])\n",
    "    cross_sec= np.zeros([num,num2]) \n",
    "    St_st1 = 1.6*St1.copy()\n",
    "    St_st1[St_st1<Re_u]=Re_u.copy()\n",
    "    St_st1[St_st1 >= 1.]=1.\n",
    "    St_st2 = 1.6*St2.copy()\n",
    "    St_st2[St_st2<Re_u]=Re_u.copy()\n",
    "    St_st2[St_st2 >= 1.]=1.\n",
    "    for i in range(0,num):\n",
    "        vel_browm[i,:] = np.sqrt((8.*Temp_g*const.k_B.cgs.value/np.pi)*(m1[i]+m2)/(m1[i]*m2))\n",
    "        vel_drift[i,:] = np.abs(u_n*2./(St1[i]+1./St1[i]) - u_n*2./(St2+1./St2))\n",
    "        vel_drift_th[i,:] = np.abs(u_n*(1./(1.+St1[i]**2.) - 1./(1.+St2**2.)))\n",
    "        st12 = np.fmax(St_st1[i],St_st2)\n",
    "        tmp1= vg2*((-St2 + St1[i])/(St2 + St1[i]))\n",
    "        tmp2 = (St1[i]**2.)/(st12 + St1[i]) - (St1[i]**2.)/(1 + St1[i]) - (St2**2.)/(st12 + St2) + (St2**2.)/(1 + St2)\n",
    "        deltav1 = tmp1*tmp2\n",
    "\n",
    "        tmp1= (St1[i]**2.)/(st12 + St1[i]) + (St2**2.)/(st12 + St2) - (St2**2.)/(Re_u + St2) - (St1[i]**2.)/(Re_u + St1[i])\n",
    "        tmp2 = 2.*(st12-Re_u)\n",
    "        deltav2 = vg2*(tmp1+tmp2)\n",
    "        vel_turb[i,:] = np.sqrt(np.abs(deltav2+deltav1))\n",
    "        cross_sec[i,:] = np.pi*(particle_1[i]+particle_2)**2.\n",
    "        \n",
    "    #X, Y = np.meshgrid(particle_1, particle_2)\n",
    "    net_vel = np.sqrt(vel_browm**2. + vel_drift**2. +vel_drift_th**2. +vel_turb**2.)\n",
    "    return net_vel,cross_sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Disk_process(object):\n",
    "    '''A generic parent class - set up the disk on a chosen 2d grid (can later make 3d is needed .. )\n",
    "    Every process object has a set of state variables on a spatial grid.\n",
    "    Generally pass the state as a dictionary of ndarray  - one state is size_dist_grid.. -> original\n",
    "    '''\n",
    "    def __init__(self, axis=None,state=None,initial_size_dist=None):\n",
    "        if axis is None :\n",
    "                raise ValueError('Must pass an axis class object ..')\n",
    "        self.process_name = 'TwoD_disk'\n",
    "        self.numdims = 2\n",
    "        setattr(self, axis.axis_type, axis)\n",
    "        self.shape = axis.shape\n",
    "        self.state = state\n",
    "        # dictionary of model parameters\n",
    "        print('Setting constants to default')\n",
    "        self.param = self.get_constants()\n",
    "        self.param['max_size_cascade'] = self.state['size_dist_grid'].max()\n",
    "        self.param['min_size_cascade'] = self.state['size_dist_grid'].min()\n",
    "        self.param['max_part_size'] = self.state['size_dist_grid'].max()\n",
    "        self.calculate_norm(initial_size_dist)\n",
    "        self.param['init_point_val'] = self.state['size_dist'][0]\n",
    "        self.param['volume'] = axis.area_all*self.param['h_disk_dust']*const.au.cgs.value**2.\n",
    "        self.state['rhogN'] = (1./np.sqrt(2.*np.pi))*self.param['mean_density_G']/self.param['H_disk'] # Gas Volume Density\n",
    "        self.state['st_grid'] = self.func_St_particle(self.state['size_dist_grid'])\n",
    "        self.param['Max_St_Cascade'] = self.state['st_grid'].max()\n",
    "        self.param['step_count'] = 0\n",
    "        self.param['Area_all'] = axis.area_all*const.au.cgs.value**2.\n",
    "        self.param['regrid_size'] = 200\n",
    "        self.param['dm_0'] = (4.*self.param['mean_density_grain']*np.pi/3.)*(self.param['min_size_cascade']**3.) - \\\n",
    "                             (4.*self.param['mean_density_grain']*np.pi/3.)*((self.param['min_size_cascade']*0.95)**3.)\n",
    "        self.param['dist_size_orig'] = self.state['size_dist_grid'].shape[0]\n",
    "        dn_grid = self.grid_dN(self.state['size_dist'],self.state['size_dist_grid'])\n",
    "        self.state['size_dist_dm_int'] = dn_grid\n",
    "\n",
    "    def get_constants(self):\n",
    "        alpha_slope = 2.1 # Slope of the bkg cascade - this remains fixed in the calc ..\n",
    "        dust_to_gas = 0.01 # Initial dust to gas ratio\n",
    "        # ( Set's the surface density of the dust - integrated over all the sizes .. )\n",
    "        alphav = 0.01\n",
    "        R_dust = np.mean(self.TwoD_cyl.points_r)\n",
    "        sigma_r,t_gas_r,c_s,t_L,L_Scale,vel_L, t_kol,l_kol,v_kol,Re,lmfp,v_k,H_disk = \\\n",
    "        mmsn_model(R_dust,alphav,Sigma1 =1700.,T1 = 270.)\n",
    "        Mach_n = v_k/c_s\n",
    "        a_val = 0.5 # for compressive, 1./3. for solenoidal\n",
    "        density_disp = np.sqrt(np.log(1. + a_val*Mach_n))\n",
    "        t_violent_relax = 1. # in Kepler times i.e. 2.*pi/omega\n",
    "        max_size_cascade = 1. # 1 cm\n",
    "        min_size_cascade = 1e-4 # 1 micron\n",
    "        mean_density_grain = 3. # gm/cm^3\n",
    "        omega = c_s/H_disk # orbital angular velocity\n",
    "        St_cnst1 = mean_density_grain*omega/c_s\n",
    "        mean_mol_weigth = 2.4*const.m_p.cgs.value\n",
    "        mfp_const = mean_mol_weigth/2e-15/np.sqrt(2.)                 # Gas mean Free Path\n",
    "        St_cnst2 = (4./9.)*1e-15*(mean_density_grain*omega)/(mean_mol_weigth*c_s)\n",
    "        max_mass_ratio = 0.001 # rule 1 (destroy wihting a threshold of 1/1000th of the mass)\n",
    "        max_vel_grow = 10.*1e2 # rule 1 (destroy if velocity > 50 m/s)\n",
    "        return {'dust_to_gas':dust_to_gas,'mean_density_G':sigma_r,'density_disp':density_disp,'t_gas_r':t_gas_r,\n",
    "        'c_s':c_s,'t_L':t_L,'L_Scale':L_Scale,'vel_L':vel_L,'t_kol':t_kol,'l_kol':l_kol,'v_kol':v_kol,'Re':Re,\n",
    "        'lmfp':lmfp,'mean_density_grain':mean_density_grain,'omega':omega,'alphav':alphav,\n",
    "        't_violent_relax':t_violent_relax,'h_disk_dust':H_disk*0.25,'alpha_slope':alpha_slope,\n",
    "               'mfp_const':mfp_const,'St_cnst1':St_cnst1,'St_cnst2':St_cnst2, 'H_disk':H_disk,'max_mass_ratio':max_mass_ratio,\n",
    "               'max_vel_grow':max_vel_grow,'R_dust':R_dust}\n",
    "\n",
    "    # Note that the normalization is defined such that the surface mass density matches\n",
    "    #  what is given (matches it at the mean value)\n",
    "    def calculate_norm(self,initial_size_dist=None):\n",
    "        if self.param['alpha_slope'] == 2 :\n",
    "            raise ValueError('slope cannot be exactly 2')\n",
    "        dust_density = self.param['dust_to_gas']*self.param['mean_density_G']\n",
    "        t1 = 2. - self.param['alpha_slope']\n",
    "        m_max = (4.*np.pi/3.)*self.param['mean_density_grain']*(self.param['max_size_cascade']**3.)\n",
    "        m_min = (4.*np.pi/3.)*self.param['mean_density_grain']*(self.param['min_size_cascade']**3.)\n",
    "        t2 = (1./t1)*(m_max**t1 - m_min**t1)\n",
    "        t3 = dust_density/(self.param['h_disk_dust'])\n",
    "        self.param['norm_param'] = t3/t2\n",
    "        if initial_size_dist is None :\n",
    "            self.state['size_dist'] = self.nm_pl((4.*np.pi*self.param['mean_density_grain']*self.state['size_dist_grid']**3.)/3.)\n",
    "        else :\n",
    "            self.state['size_dist'] = initial_size_dist.copy()\n",
    "\n",
    "    def nm_pl(self,m) :  # Specify a power law as the n(m) = m^{-alpha}, properly normalized\n",
    "        p1 = self.param['norm_param']*(m**(-self.param['alpha_slope']))\n",
    "        return p1  # return num/volume/mass\n",
    "\n",
    "    def func_St_particle(self,particle_grid,gas_density=None,single=None):\n",
    "        if gas_density is None :\n",
    "            gas_density = self.state['rhogN']\n",
    "        St1_grid = (particle_grid)*(self.param['St_cnst1']/gas_density)\n",
    "        mfp = self.param['mfp_const']/gas_density              # Gas mean Free Path\n",
    "        if (single ==1) :\n",
    "            if (particle_grid > mfp*9./4.):\n",
    "                St1_grid = self.param['St_cnst2']*(particle_grid)**2.\n",
    "            return St1_grid\n",
    "        tmp1 = np.where(particle_grid > mfp*9./4.)\n",
    "        St1_grid[tmp1] = self.param['St_cnst2']*(particle_grid[tmp1])**2.  # Stokes Drag Regime\n",
    "        return St1_grid\n",
    "\n",
    "    def func_St_particle_invert(self,St_num,gas_density=None):\n",
    "        if gas_density is None :\n",
    "            gas_density = self.state['rhogN']\n",
    "        particle_grid = St_num/(self.param['St_cnst1']/gas_density)\n",
    "        mfp = self.param['mfp_const']/gas_density              # Gas mean Free Path\n",
    "        if(particle_grid > mfp*9./4.):\n",
    "            particle_grid = np.sqrt(St_num/self.param['St_cnst2'])  # Stokes Drag Regime\n",
    "        return particle_grid\n",
    "\n",
    "    def reset_density(self):\n",
    "        self.state['rhogN'] = (1./np.sqrt(2.*np.pi))*self.param['mean_density_G']/self.param['H_disk'] # Gas Volume Density\n",
    "        return 1\n",
    "\n",
    "    def G_tm(self,dn_grid,size_dist_grid,st_num_grid,tmp1,sigmaG_sc,R_dust) :  #only dm/dt\n",
    "        ##  dm/dt - G\n",
    "        m_tm = (4.*self.param['mean_density_grain']*np.pi/3.)*(size_dist_grid**3.) # mass of the particles in the grid\n",
    "        #dm_grid = np.diff(m_tm)\n",
    "        #integrnd_D = dn_grid.copy()\n",
    "        net_vel,cross_sec = rel_velocity_grd(size_dist_grid[tmp1],size_dist_grid,1.,R_dust,self.param['t_gas_r'],\\\n",
    "                             alphav = self.param['alphav'],sigmaD = self.param['mean_density_G']*sigmaG_sc,\\\n",
    "                             psi=self.param['dust_to_gas'],H_disk = self.param['H_disk'],\\\n",
    "                         rhod1=self.param['mean_density_grain'],rhod2=self.param['mean_density_grain'],\\\n",
    "                         St1=st_num_grid[tmp1],St2=st_num_grid)\n",
    "        m_tm_act = np.tile(m_tm,(net_vel.shape[0],1))\n",
    "        m_tm_act1 = np.transpose(np.tile(m_tm[tmp1],(net_vel.shape[1],1)))*self.param['max_mass_ratio'] # impose the mass-cutoff\n",
    "        m_tm_act2 = m_tm_act1/self.param['max_mass_ratio']*1.1\n",
    "        m_tm_act_filt = m_tm_act.copy()*0.0 + 1.\n",
    "        m_tm_act_filt[m_tm_act<m_tm_act1] = 0.\n",
    "        m_tm_act_filt = 1. - m_tm_act_filt\n",
    "        m_tm_act_filt[net_vel<self.param['max_vel_grow']] = 1.  # This is the rule that destroy only if velocity > 50 m/s)\n",
    "        m_tm_act_filt[m_tm_act>m_tm_act2] = 0.\n",
    "        net_vel_cross2 = ((net_vel*cross_sec)*m_tm_act)*m_tm_act_filt\n",
    "        tmp1 = net_vel_cross2[:,1:]*dn_grid[1:]\n",
    "        dm_G = np.sum(tmp1,axis=1)\n",
    "        return dm_G,m_tm[-1]\n",
    "\n",
    "    def G_D_tm(self,dn_grid,size_dist_grid,st_num_grid,tmp1,sigmaG_sc,R_dust) :  # D destruction time-scale (in seconds)\n",
    "        ## D - timescale, dm/dt - G\n",
    "        net_vel,cross_sec = rel_velocity_grd(size_dist_grid[tmp1],size_dist_grid,1.,R_dust,self.param['t_gas_r'],\\\n",
    "                             alphav = self.param['alphav'],sigmaD = self.param['mean_density_G']*sigmaG_sc,\\\n",
    "                             psi=self.param['dust_to_gas'],H_disk = self.param['H_disk'],\\\n",
    "                         rhod1=self.param['mean_density_grain'],rhod2=self.param['mean_density_grain'],\\\n",
    "                         St1=st_num_grid[tmp1],St2=st_num_grid)\n",
    "        m_tm = (4.*self.param['mean_density_grain']*np.pi/3.)*(size_dist_grid**3.) # mass of the particles in the grid\n",
    "        # integrnd_D = dn_grid.copy()\n",
    "        net_vel_D_filt = net_vel.copy()*0.0 + 1.\n",
    "        m_tm_act = np.tile(m_tm,(net_vel.shape[0],1))\n",
    "        m_tm_act1 = np.transpose(np.tile(m_tm[tmp1],(net_vel.shape[1],1)))*self.param['max_mass_ratio'] # impose the mass-cutoff\n",
    "        m_tm_act2 = (m_tm_act1/self.param['max_mass_ratio'])*1.1\n",
    "        m_tm_act_filt = m_tm_act.copy()*0.0 + 1.\n",
    "        net_vel_D_filt[net_vel<self.param['max_vel_grow']] =0.  # This is the rule that destroy only if velocity > 50 m/s)\n",
    "        m_tm_act_filt[m_tm_act<m_tm_act1] = 0.\n",
    "        #m_tm_act_filt[m_tm_act>m_tm_act2] = 0.\n",
    "        net_vel_cross = ((net_vel*cross_sec)*net_vel_D_filt)*m_tm_act_filt\n",
    "        tmp1 = net_vel_cross[:,1:]*dn_grid[1:]\n",
    "        sm = np.sum(tmp1,axis=1)\n",
    "        sm[sm==0] = -1\n",
    "        t_D = 1./sm\n",
    "\n",
    "        m_tm_act_filt = 1. - m_tm_act_filt\n",
    "        m_tm_act_filt[net_vel<self.param['max_vel_grow']] = 1.  # This is the rule that destroy only if velocity > 50 m/s)\n",
    "        m_tm_act_filt[m_tm_act>m_tm_act2] = 0. # Get destroyed by anybody larger than you by at least 10% ...\n",
    "        net_vel_cross2 = ((net_vel*cross_sec)*m_tm_act)*m_tm_act_filt\n",
    "        tmp1 = net_vel_cross2[:,1:]*dn_grid[1:]\n",
    "        dm_G = np.sum(tmp1,axis=1)\n",
    "        return t_D,dm_G\n",
    "\n",
    "    def rule1_growth_dest(self,dn_grid,size_dist_grid,st_num_grid,tmp1,new_dens_sc,time_step,r_val,only_D = 0.):\n",
    "        '''\n",
    "        implement rule 1 here ..\n",
    "        '''\n",
    "        calc_D_val,calc_G_val = self.G_D_tm(dn_grid,size_dist_grid,st_num_grid,tmp1,\\\n",
    "                                      new_dens_sc,r_val)  # output is D (in sec) and dm/dt\n",
    "        calc_D_val = calc_D_val/time_step   # Non-dimensional ..\n",
    "        tmp2 = np.where((calc_D_val <= 1.) & (calc_D_val > 0.))\n",
    "        indx_rem = tmp1[0][tmp2[0]]\n",
    "        dn_grid[indx_rem] = 0.       # Not conserving mass here (Bad ... )\n",
    "        tmp2 = np.where((calc_D_val > 1.) & (calc_D_val <= 100.))\n",
    "        indx_rem = tmp1[0][tmp2[0]]\n",
    "        dn_grid[indx_rem] = dn_grid[indx_rem]*(1. - np.exp(-calc_D_val[tmp2]/20.))        # Not conserving mass here (Bad ... )\n",
    "        ######### tmp3 = tmp1[0][tmp2[0]]\n",
    "        ######### tmp4 = np.where(size_dist_grid < 1e3) # only dest for <1e3\n",
    "        ######### indx_rem = np.intersect1d(tmp3,tmp4[0])\n",
    "        ## For the rest (where D/time-step > 1,\n",
    "        # i.e would not be destroyed in mean at least (can have Poisson stats here))\n",
    "        if only_D != 1 :\n",
    "            tmp2 = np.where((calc_D_val > 1.) | (calc_D_val <= 0.))\n",
    "            indx_rem = tmp1[0][tmp2[0]]\n",
    "            delta_m = calc_G_val[tmp2]*time_step # Not conserving mass here (Bad ... )\n",
    "            delta_m2 = delta_m/(4.*np.pi*self.param['mean_density_grain']/3.)\n",
    "            delta_r = (size_dist_grid[indx_rem]**3. +  delta_m2)**(1./3.) - size_dist_grid[indx_rem] #    delta_r\n",
    "            for i in range(indx_rem.shape[0]-1):\n",
    "                if size_dist_grid[indx_rem[i]]+delta_r[i] == size_dist_grid[indx_rem[i]+1] :\n",
    "                    print('Duplicate ... - fixed ')  ## Check for duplicates in the new size_grid ..\n",
    "                    delta_r[i] = delta_r[i]*.99\n",
    "            if ( delta_r < 0.).any():\n",
    "                print('negative delta_r - BAD ...')\n",
    "            size_dist_grid[indx_rem]  += delta_r\n",
    "            tmp1 = np.argsort(size_dist_grid)\n",
    "            size_dist_grid = size_dist_grid[tmp1]\n",
    "            dn_grid = dn_grid[tmp1]\n",
    "        if (dn_grid<0).any():\n",
    "            raise ValueError('Error - negative number dN - BAD ... ')  ## Check for any negatives - bad ...\n",
    "        return dn_grid,size_dist_grid\n",
    "\n",
    "    def grid_dN(self,size_dist,size_dist_grid): # get dN/volume grid instead of dN/dm/volume which is the original power-law ..\n",
    "        m_tm = (4.*self.param['mean_density_grain']*np.pi/3.)*(size_dist_grid**3.) # mass of the particles in the grid\n",
    "        dm_grid = np.diff(m_tm)\n",
    "        dn_grid = size_dist[1:]*dm_grid # this is the dN/volume grid (size is 1 less than the size_dist_grid .. )\n",
    "        dn_grid = np.insert(dn_grid,0,self.param['dm_0']*size_dist[0]) # prepend a slope*.05 times slope of first part for the dn_grid to make it the same size as size_dist_grid\n",
    "        return dn_grid\n",
    "\n",
    "    def rule2_growth(self,size_max_cascade,dn_grid,size_dist_grid,st_num_grid,new_dens_sc,time_step,r_val,gas_density_inp):\n",
    "        '''\n",
    "        implement rule 2 here ..\n",
    "        '''\n",
    "        size_dist = new_dens_sc*self.state['size_dist'].copy()\n",
    "        new_size_growth = size_dist_grid.max()\n",
    "        time_counter = 0.\n",
    "        first_pass_max_cas = 0.\n",
    "        dn_grid_New = dn_grid.copy()\n",
    "        # Note that the following stops if mass doubling time is greater than time-step\n",
    "        # Make a note of when the size exceeds size_max_cascade, we stop growing (can introduce a destruction term later .. )\n",
    "        while (time_counter <= 1.) : # really not used ...\n",
    "            new_size_growth = (2.**(1./3.))*size_dist_grid[-1]\n",
    "            tmp1 = np.array([-1])\n",
    "            calc_G_val,m_lrg = self.G_tm(dn_grid_New,size_dist_grid,st_num_grid,tmp1,\\\n",
    "                                          new_dens_sc,r_val)\n",
    "            if calc_G_val ==0:\n",
    "                time_dbl = 2.\n",
    "            else :\n",
    "                time_dbl = (m_lrg/calc_G_val)/time_step   # Non-dimensional ..\n",
    "            time_counter += time_dbl\n",
    "            if (time_counter > 1.):  # as long as the cumulative  mass doubling time is greater than 1\n",
    "                break\n",
    "            tmp1 = self.nm_pl((4.*np.pi*self.param['mean_density_grain']*size_dist_grid[-1]**3.)/3.)\n",
    "            scale_fac = size_dist[-1]/tmp1  # this takes care of the diff btw the scales and normalizations ..\n",
    "            size_dist_grid = np.append(size_dist_grid,new_size_growth)\n",
    "            ############################################\n",
    "            new_size_dist = scale_fac*\\\n",
    "            self.nm_pl((4.*np.pi*self.param['mean_density_grain']*new_size_growth**3.)/3.)\n",
    "            size_dist = np.append(size_dist,new_size_dist)\n",
    "            dn_grid_New = self.grid_dN(size_dist,size_dist_grid)\n",
    "            ############################################\n",
    "            st_new_grwth = self.func_St_particle(new_size_growth,gas_density = gas_density_inp,single=1)\n",
    "            st_num_grid = np.append(st_num_grid,st_new_grwth)\n",
    "            ############################################\n",
    "            ## This is for later if we want to also introduce a destruction for some fraction of the time-step (too detailed .. for our purposes)\n",
    "            if (new_size_growth >= size_max_cascade) & (first_pass_max_cas ==0.) :\n",
    "                first_pass_max_cas = 1. - time_counter\n",
    "                break\n",
    "        # No need to do regiding here (just save this and regrid at end of the time-step)\n",
    "        #mp1 = np.where(st_num_grid >= self.param['Max_St_Cascade'])\n",
    "        #ize_dist_grid_N = np.logspace(np.log10(size_dist_grid.min()),np.log10(size_dist_grid.max()),self.param['regrid_size'])\n",
    "        #ize_dist_N = self.regrid(size_dist,size_dist_grid,size_dist_grid_N)\n",
    "        return dn_grid_New,size_dist_grid #tmp1,first_pass_max_cas\n",
    "\n",
    "    def regrid(self,dn_grid,size_dist_grid,new_size_dist_grid):\n",
    "        new_dn_grid = new_size_dist_grid.copy()*0.0\n",
    "        new_size_da = new_size_dist_grid.copy()*0.0\n",
    "        new_size_dist = new_size_dist_grid.copy()*0.0\n",
    "        new_dn_grid[0] = dn_grid[0]\n",
    "        for i in range(1,new_size_dist_grid.shape[0]):\n",
    "            tmp1 = np.where((size_dist_grid > new_size_dist_grid[i-1]) & (size_dist_grid <= new_size_dist_grid[i]))\n",
    "            new_dn_grid[i] = np.sum(dn_grid[tmp1])\n",
    "        m_tm = (4.*self.param['mean_density_grain']*np.pi/3.)*(new_size_dist_grid**3.) # mass of the particles in the grid\n",
    "        dm_grid = np.diff(m_tm)  # Note the size is one smaller than new_dn_grid\n",
    "        da_grid = np.diff(new_size_dist_grid) # Note the size is one smaller than new_dn_grid\n",
    "        #####################\n",
    "        new_size_da[0] = new_dn_grid[0]/(0.05*new_size_dist_grid[0])\n",
    "        new_size_da[1:] = new_dn_grid[1:]/da_grid\n",
    "        #####################\n",
    "        new_size_dist[0] = new_dn_grid[0]/self.param['dm_0']\n",
    "        new_size_dist[1:] = new_dn_grid[1:]/dm_grid\n",
    "        #####################\n",
    "        tmp_del = np.where((new_dn_grid*self.param['volume'])<= 1e-2)\n",
    "        new_size_dist  = np.delete(new_size_dist, tmp_del)\n",
    "        new_size_da  = np.delete(new_size_da, tmp_del)\n",
    "        new_dn_grid  = np.delete(new_dn_grid, tmp_del)\n",
    "        new_size_dist_grid  = np.delete(new_size_dist_grid, tmp_del)\n",
    "        return new_size_dist,new_size_da,new_dn_grid,new_size_dist_grid\n",
    "\n",
    "    def step_forward(self):\n",
    "        '''\n",
    "        Call this after every time-step ... - time-step is t_violent_relax\n",
    "        '''\n",
    "        mean_dd = self.param['dust_to_gas']*self.param['mean_density_G']\n",
    "        mean_gd = self.param['mean_density_G']\n",
    "        mu = np.log(self.param['mean_density_G']) - .5*self.param['density_disp']**2.\n",
    "        new_dens_sc =  (np.random.lognormal(mu,self.param['density_disp'],self.TwoD_cyl.area_grid.shape))/mean_gd\n",
    "        # note that this should be scaled by grid area ...\n",
    "        self.state['scale'] = new_dens_sc.copy()\n",
    "        self.state['rhogNew']= self.state['rhogN']*new_dens_sc       # This is gas density in each grid bin ..\n",
    "        size_dist_dm_int_New = self.state['size_dist_dm_int'].copy()*0.0 # this is the dN grid ..\n",
    "        size_dist_grid_New =  self.state['size_dist_grid'].copy()\n",
    "        #########################################\n",
    "        # Set-up the size distribution - how to distribute from overall distrib after a time-step ..\n",
    "        #########################################\n",
    "        # Evolve in each grid bin separately -\n",
    "        # Rule : If the size distrib in the grid has St greater than self.param['Max_St_Cascade'],\n",
    "        # then calculate the D (Destruction time in units of time_step) - do this for all St > ma_st_cascade\n",
    "        # As long as D is smaller than 1 (i.e. smaller than timestep), remove all the particles of that mass/size\n",
    "        # else allow growth of the particle as rho*sigma*v ..\n",
    "        # Second Rule - For cases where St max is < Max_St_cascade -> calculate the G timescale -\n",
    "        # time to double the mass in units of time-step. As long as G<1 keep doubling mass of the system until\n",
    "        # hitting max_St_Cascade*2. Then the first rule works ..\n",
    "        #\n",
    "        # Other choices :\n",
    "        # a. how to set cascade in Rule 2 : Fix the normalization so that same number of particles at end of cascade at originally\n",
    "        #    at largest size (i.e. assume all the largest particles grow to bigger sizes + fill from bkg influx)\n",
    "        # b. How to distribute the mass of the destroyed particles ? -\n",
    "        #     ideally integrate mass and put it all in the cascade, currently just removed and put in the 'bkg'.\n",
    "        # c. Anything else ?? - Choose that Destruction (D) only by particles within 1/100th of the mass and with velocities of\n",
    "        #    at least 50 m/s (can change both of these later). Similarly for G (grow due to everything with either mass < 1/100th )\n",
    "        #    or velocity less than 50 m/s.\n",
    "        #\n",
    "        #  Note - not conserving mass currently\n",
    "        #########################################\n",
    "        r_val = self.TwoD_cyl.points_r.mean()\n",
    "        time_step = (self.param['t_violent_relax']*2.*np.pi/self.param['omega'])\n",
    "        for i in range(self.state['scale'].shape[0]) :\n",
    "            for k in range(self.state['scale'].shape[1]):\n",
    "                size_dist_dm_int = new_dens_sc[i,k]*self.state['size_dist_dm_int'].copy()\n",
    "                size_dist_grid = self.state['size_dist_grid'].copy()\n",
    "                st_num_grid = self.func_St_particle(size_dist_grid,gas_density = self.state['rhogNew'][i,k])\n",
    "                tmp1 = np.where(st_num_grid > self.param['Max_St_Cascade'])\n",
    "                if np.size(tmp1) != 0:\n",
    "                    #a1 = timeit.timeit()\n",
    "                    size_dist_dm_int,size_dist_grid = \\\n",
    "                    self.rule1_growth_dest(size_dist_dm_int,size_dist_grid,st_num_grid,tmp1,new_dens_sc[i,k],\\\n",
    "                                      time_step,r_val,only_D = 0.)\n",
    "                    #print('R1: ',timeit.timeit() - a1)\n",
    "                else:\n",
    "                    #a1 = timeit.timeit()\n",
    "                    ## Now in the regime of Rule 2 since nothing is larger than the cascade end ..\n",
    "                    size_max_cascade = self.func_St_particle_invert(self.param['Max_St_Cascade'],\\\n",
    "                                    gas_density=self.state['rhogNew'][i,k])\n",
    "                    size_dist_dm_int,size_dist_grid = \\\n",
    "                    self.rule2_growth(size_max_cascade,size_dist_dm_int,size_dist_grid,st_num_grid,new_dens_sc[i,k],\\\n",
    "                                     time_step,r_val,self.state['rhogNew'][i,k])\n",
    "                    #\n",
    "                    #print('R2: ',timeit.timeit() - a1)\n",
    "                    # For the rest of the time-step (after the max_cascade is reached .. -> can have destruction also ..)\n",
    "                    #if (first_pass_max_cas < 1) & (first_pass_max_cas>0.05):\n",
    "                    #    st_num_grid = self.func_St_particle(size_dist_grid,gas_density = self.state['rhogNew'][i,k])\n",
    "                    #    size_dist,size_dist_grid = \\\n",
    "                    #    self.rule1_growth_dest(self,size_dist,size_dist_grid,st_num_grid,tmp1,new_dens_sc[i,k],\\\n",
    "                    #                  time_step*first_pass_max_cas,r_val,only_D = 1)\n",
    "                    ############################################\n",
    "                #### end of else here ...\n",
    "                #a1 = timeit.timeit()\n",
    "                tmp1 = np.in1d(size_dist_grid_New, size_dist_grid, assume_unique=True) # index of size_dist_grid_New\n",
    "                tmp1b = np.in1d(size_dist_grid,size_dist_grid_New, assume_unique=True)  # index of size_dist_grid\n",
    "                size_dist_dm_int_New[tmp1] += size_dist_dm_int[tmp1b]\n",
    "                # then merge other size_dist_grid\n",
    "                inv_tmp1b = np.invert(tmp1b)\n",
    "                del tmp1,tmp1b\n",
    "                size_dist_grid_New = np.append(size_dist_grid_New,size_dist_grid[inv_tmp1b])\n",
    "                size_dist_dm_int_New = np.append(size_dist_dm_int_New,size_dist_dm_int[inv_tmp1b])\n",
    "                # sort it to make sure ascending sequence\n",
    "                tmp1 = np.argsort(size_dist_grid_New)\n",
    "                size_dist_grid_New = size_dist_grid_New[tmp1]\n",
    "                size_dist_dm_int_New = size_dist_dm_int_New[tmp1]\n",
    "                del size_dist_grid,size_dist_dm_int\n",
    "                #print('R3: ',timeit.timeit() - a1)\n",
    "        # Assume that the first point of the new grid is same as the original grid\n",
    "        #a1 = timeit.timeit()\n",
    "        print('Max_part : ',size_dist_grid_New.max()/1e6)\n",
    "        if (size_dist_grid_New.max() > self.param['max_size_cascade']*1.05):\n",
    "            size_dist_grid_N = np.append(\\\n",
    "            np.logspace(np.log10(self.param['min_size_cascade']),np.log10(self.param['max_size_cascade']),self.param['dist_size_orig']),\\\n",
    "            np.logspace(np.log10(self.param['max_size_cascade'])*1.02,np.log10(2e5),self.param['regrid_size']))\n",
    "            size_dist_grid_N = np.append(size_dist_grid_N,np.array([3e5,4e5,5e5,6e5,7e5,8e5,9e5,1e6,2e6,5e6,7e6,1e7,3e7,5e7,1e8]))\n",
    "        else :\n",
    "            size_dist_grid_N = np.logspace(np.log10(self.param['min_size_cascade']),np.log10(size_dist_grid_New.max()),self.param['dist_size_orig'])\n",
    "        size_dist_N,new_size_da,size_dist_dm_int,size_dist_grid_N = self.regrid(size_dist_dm_int_New,size_dist_grid_New,size_dist_grid_N)\n",
    "        ## At the end of the time-step -->\n",
    "        self.state['size_dist'] = size_dist_N/self.state['scale'].sum()  # Note that size_dist_New has to be corrected for the scaling to restore back ..\n",
    "        self.state['size_dist_grid'] = size_dist_grid_N # The new corresponding grid ...\n",
    "        self.param['step_count'] +=1\n",
    "        self.param['max_part_size'] = size_dist_grid_N.max()\n",
    "        self.state['size_dist_da'] = new_size_da/self.state['scale'].sum()\n",
    "        self.state['size_dist_dm_int'] = size_dist_dm_int/self.state['scale'].sum()\n",
    "        #print('R4: ',timeit.timeit() - a1)\n",
    "        tmp1A = np.argmin(1e3 >= size_dist_grid_N )\n",
    "        print('Num_part : ',np.sum(size_dist_dm_int[tmp1A:])*self.param['volume']/new_dens_sc.sum(),'  ',tmp1A)\n",
    "        #print('Done, step_number : ',self.param['step_count'],'  ',size_dist_grid_New.max())\n",
    "        #scale_fact = self.param['init_point_val']/self.state['size_dist'][0]\n",
    "        #print(scale_fact),\n",
    "        #self.state['size_dist'] = scale_fact*self.state['size_dist']\n",
    "        #a1 = self.reset_density()\n",
    "        return 1\n",
    "        #############################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting constants to default\n",
      "2.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e7dfcb1b470a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mdisk1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-4fa45b6092b2>\u001b[0m in \u001b[0;36mstep_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                     \u001b[1;31m#a1 = timeit.timeit()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                     \u001b[0msize_dist_dm_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize_dist_grid\u001b[0m \u001b[1;33m=\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrule1_growth_dest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_dist_dm_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize_dist_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst_num_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_dens_sc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m                                      \u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0monly_D\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m                     \u001b[1;31m#print('R1: ',timeit.timeit() - a1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-4fa45b6092b2>\u001b[0m in \u001b[0;36mrule1_growth_dest\u001b[1;34m(self, dn_grid, size_dist_grid, st_num_grid, tmp1, new_dens_sc, time_step, r_val, only_D)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mtmp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_D_val\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcalc_D_val\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m100.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mindx_rem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mdn_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindx_rem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdn_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindx_rem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcalc_D_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m20.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# Not conserving mass here (Bad ... )\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0msss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m######### tmp3 = tmp1[0][tmp2[0]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp' is not defined"
     ]
    }
   ],
   "source": [
    "ax1 = Axis(bounds_r=np.array([.9,1.1]),bounds_phi=np.array([0.,2.*np.pi]),delta_r=.05,delta_phi=np.pi/18.)\n",
    "\n",
    "#grid = np.append(np.array([1e-4,2e-4,1e-3,1e-2]),np.logspace(-1,.1,100))\n",
    "grid = np.logspace(-4,.1,100)\n",
    "disk1 = Disk_process(axis =ax1,state={'size_dist_grid':grid})\n",
    "#tmp1 = disk1.state['size_dist'].copy()\n",
    "print(disk1.param['alpha_slope'])\n",
    "#disk1.param['alpha_slope'] = 1.8\n",
    "#disk1.calculate_norm()\n",
    "#disk1.param['init_point_val'] = disk1.state['size_dist'][0]\n",
    "#dn_grid = disk1.grid_dN(disk1.state['size_dist'],disk1.state['size_dist_grid'])\n",
    "#disk1.state['size_dist_dm_int'] = dn_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "orig = disk1.state['size_dist_dm_int'],disk1.state['size_dist_grid']\n",
    "#orig1 = disk1.state['size_dist_da'],disk1.state['size_dist_grid']\n",
    "#orig2 = disk1.state['size_dist'],disk1.state['size_dist_grid']\n",
    "\n",
    "for i in range(120):\n",
    "    disk1.step_forward()\n",
    "    print(i)\n",
    "    if i%20 ==0:\n",
    "        plt.loglog(orig[1][1:],orig[0][1:]*disk1.param['volume'],'r+')\n",
    "        new2 = disk1.state['size_dist_dm_int'],disk1.state['size_dist_grid']\n",
    "        plt.loglog(new2[1][1:],new2[0][1:]*disk1.param['volume'],marker='o',linestyle='None')\n",
    "        plt.title('time-step : '+str(disk1.param['step_count']))\n",
    "        plt.xlabel(' Size  - cm')\n",
    "        plt.ylabel(' dN (over the volume of annulus of .2 AU at 1 AU)')\n",
    "    #plt.savefig('Run1/Run1_stp'+str(i)+'_intm.png')\n",
    "    #plt.clf()\n",
    "    #############################################################################################################\n",
    "    #plt.loglog(orig1[1][1:],orig1[0][1:]*disk1.param['volume'],'r+')\n",
    "    #new2 = disk1.state['size_dist_da'],disk1.state['size_dist_grid']\n",
    "    #plt.loglog(new2[1][1:],new2[0][1:]*disk1.param['volume'],marker='o',linestyle='None')\n",
    "    #plt.title('time-step : '+str(disk1.param['step_count']))\n",
    "    #plt.xlabel(' Size  - cm')\n",
    "    #plt.ylabel(' dN/da (over the volume of annulus of .2 AU at 1 AU)')\n",
    "    #plt.savefig('Run1/Run1_stp'+str(i)+'_da.png')\n",
    "    #plt.clf()\n",
    "    #############################################################################################################\n",
    "    #plt.loglog(orig2[1][1:],orig2[0][1:]*disk1.param['volume'],'r+')\n",
    "    #new2 = disk1.state['size_dist'],disk1.state['size_dist_grid']\n",
    "    #plt.loglog(new2[1][1:],new2[0][1:]*disk1.param['volume'],marker='o',linestyle='None')\n",
    "    #plt.title('time-step : '+str(disk1.param['step_count']))\n",
    "    #plt.xlabel(' Size  - cm')\n",
    "    #plt.ylabel(' dN/dm (over the volume of annulus of .2 AU at 1 AU)')\n",
    "    #plt.savefig('Run1/Run1_stp'+str(i)+'_dm.png')\n",
    "    #plt.clf()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disk2 = Disk_process(axis =ax1,state={'size_dist_grid':disk1.state['size_dist_grid']},\\\n",
    "                     initial_size_dist=disk1.state['size_dist'])\n",
    "disk2.param['max_size_cascade'] = disk1.param['max_size_cascade']\n",
    "disk2.param['min_size_cascade'] = disk1.param['min_size_cascade']\n",
    "disk2.param['Max_St_Cascade'] = disk1.param['Max_St_Cascade']\n",
    "disk2.param['norm_param'] = disk1.param['norm_param']\n",
    "disk2.param['regrid_size'] = 200\n",
    "## destruction parameters\n",
    "disk2.param['max_mass_ratio'] = 0.01 # ie. within 1/100 th of the mass\n",
    "disk2.param['max_vel_grow'] = 20.*1e2 # 10 m/s\n",
    "\n",
    "num_steps = 5\n",
    "for i in range(num_steps):\n",
    "    disk2.step_forward()\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "size_dist_New= disk1.state['size_dist']\n",
    "size_dist_grid_New = disk1.state['size_dist_grid']\n",
    "size_dist_grid_N = np.append(\\\n",
    "            np.logspace(np.log10(disk1.param['min_size_cascade']),np.log10(disk1.param['max_size_cascade']),disk1.param['dist_size_orig']),\\\n",
    "            np.logspace(np.log10(disk1.param['max_size_cascade'])*1.02,np.log10(1e2),10))\n",
    "size_dist_grid_N = np.append(size_dist_grid_N,np.array([1e3,1e4,1e5,1e6]))\n",
    "size_dist_N,new_size_da,size_dist_dm_int,size_dist_grid_N = disk1.regrid(size_dist_New,size_dist_grid_New,size_dist_grid_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.clf()\n",
    "\n",
    "plt.loglog(orig[1][1:],orig[0][1:]*disk1.param['volume'],'r+')\n",
    "new2 = size_dist_dm_int,size_dist_grid_N\n",
    "plt.loglog(new2[1][1:],new2[0][1:]*disk1.param['volume'],marker='o',linestyle='None')\n",
    "plt.title('time-step : '+str(disk1.param['step_count']))\n",
    "plt.xlabel(' Size  - cm')\n",
    "plt.ylabel(' dN (over the volume of annulus of .2 AU at 1 AU)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1A = np.argmin(1e3 > size_dist_grid_N )\n",
    "tmp2A = np.argmax(1e6 <= size_dist_grid_N)\n",
    "tmp2A\n",
    "#print('Num_part : ',np.sum(size_dist_dm_int[tmp1A:tmp2A])*disk1.param['volume']/disk1.state['scale'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### to produce an animation ...\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# set up initial state and global variables\n",
    "ax1 = Axis(bounds_r=np.array([.9,1.1]),bounds_phi=np.array([0.,2.*np.pi]),delta_r=.05,delta_phi=np.pi/18.)\n",
    "\n",
    "grid = np.logspace(-4,.1,100)\n",
    "disk1 = Disk_process(axis =ax1,state={'size_dist_grid':grid})\n",
    "disk1.param['regrid_size'] = 200\n",
    "#disk1.param['density_disp'] = 1.\n",
    "\n",
    "## destruction parameters \n",
    "disk1.param['max_mass_ratio'] = 0.01 # ie. within 1/100 th of the mass \n",
    "disk1.param['max_vel_grow'] = 20.*1e2 # 10 m/s\n",
    "\n",
    "\n",
    "# set up figure and animation\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111) \n",
    "ax.set_autoscale_on(True) # enable autoscale\n",
    "ax.autoscale_view(True,True,True)\n",
    "\n",
    "# particles holds the locations of the particles\n",
    "particles, = ax.loglog([], [], 'o-')\n",
    "\n",
    "time_text = ax.text(0.02, 0.15, '', transform=ax.transAxes)\n",
    "max_size_text = ax.text(0.02, 0.1, '', transform=ax.transAxes)\n",
    "ax.set_xlabel(' Size  - cm')\n",
    "ax.set_ylabel(' dn/dm (over the volume of annulus of .2 AU at 1 AU)')\n",
    "\n",
    "def init():\n",
    "    \"\"\"initialize animation\"\"\"\n",
    "    particles.set_data([], [])\n",
    "    time_text.set_text('')\n",
    "    max_size_text.set_text('')\n",
    "    return particles, time_text,max_size_text\n",
    "\n",
    "def animate(i):\n",
    "    \"\"\"perform animation step\"\"\"\n",
    "    print(i)\n",
    "    global disk1\n",
    "    disk1.step_forward()\n",
    "    new2 = disk1.state['size_dist'],disk1.state['size_dist_grid']\n",
    "    tmp1 = np.where(new2[1]>1e-2)\n",
    "    particles.set_data(new2[1][tmp1],new2[0][tmp1]*disk1.param['volume'])\n",
    "    ax.relim()        # Recalculate limits\n",
    "    ax.autoscale_view(True,True,True) #Autoscale\n",
    "    time_text.set_text('time = %.1f' %  disk1.param['step_count'])\n",
    "    max_size_text.set_text('max_size = %.2f cm' % disk1.param['max_part_size'])\n",
    "    return particles, time_text, max_size_text\n",
    "\n",
    "# choose the interval based on dt and the time to animate one step\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames = 2000,repeat=False,\n",
    "                              interval=5, blit=True, init_func=init)\n",
    "ani.save('Run1/Run1.mp4', fps=5)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
